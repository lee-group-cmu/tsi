{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import dill\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.distributions import MultivariateNormal\n",
    "from sbi.inference import FMPE, SNPE, NPSE\n",
    "from sbi.analysis import pairplot\n",
    "from sbi.utils import BoxUniform\n",
    "import sbibm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lf2i.inference import LF2I\n",
    "from lf2i.test_statistics.posterior import Posterior\n",
    "from lf2i.test_statistics.waldo import Waldo\n",
    "from lf2i.calibration.critical_values import train_qr_algorithm\n",
    "from lf2i.utils.other_methods import hpd_region\n",
    "from lf2i.plot.parameter_regions import plot_parameter_regions\n",
    "from lf2i.plot.coverage_diagnostics import coverage_probability_plot\n",
    "from lf2i.plot.power_diagnostics import set_size_plot\n",
    "from tsi.common.monotone_nn import train_monotonic_nn, MonotonicNN\n",
    "from tsi.common.utils import IntList, TrainingLogger\n",
    "from tsi.temp.utils import kdeplots2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4861f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Prior: N(0, 2I)\n",
    "def log_prior(theta):\n",
    "    return multivariate_normal.logpdf(theta, mean=[0, 0], cov=2*np.eye(2))\n",
    "\n",
    "# Log-likelihood: log(0.5*N(x|theta,I) + 0.5*N(x|theta,I/10))\n",
    "def log_likelihood(x, theta):\n",
    "    ll1 = multivariate_normal.logpdf(x, theta, np.eye(2))\n",
    "    ll2 = multivariate_normal.logpdf(x, theta, 0.1*np.eye(2))\n",
    "    return np.logaddexp(ll1 + np.log(0.5), ll2 + np.log(0.5))\n",
    "\n",
    "# Log posterior (unnormalized)\n",
    "def log_posterior(theta, x):\n",
    "    return log_prior(theta) + log_likelihood(x, theta)\n",
    "\n",
    "def sample_likelihood(theta0, n_samples=10000):\n",
    "    # Sample X from likelihood at theta0\n",
    "    n1 = np.random.binomial(n_samples, 0.5)\n",
    "    x1 = np.random.randn(n1, 2) + theta0  # from N(theta0, I)\n",
    "    x2 = np.random.randn(n_samples - n1, 2) * np.sqrt(0.1) + theta0  # from N(theta0, I/10)\n",
    "    x_samples = np.vstack([x1, x2])\n",
    "    \n",
    "    return x_samples\n",
    "\n",
    "# Sample X values to get distribution of log pi(theta0 | X)\n",
    "def sample_log_posterior_dist(theta0, n_samples=10000):\n",
    "    # Sample X from likelihood at theta0\n",
    "    n1 = np.random.binomial(n_samples, 0.5)\n",
    "    x1 = np.random.randn(n1, 2) + theta0  # from N(theta0, I)\n",
    "    x2 = np.random.randn(n_samples - n1, 2) * np.sqrt(0.1) + theta0  # from N(theta0, I/10)\n",
    "    x_samples = np.vstack([x1, x2])\n",
    "    \n",
    "    # Compute log posterior for each X\n",
    "    log_posts = np.array([log_posterior(theta0, x) for x in x_samples])\n",
    "    return log_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_joint_distribution(which_dist, B):\n",
    "    if which_dist == 'prior':\n",
    "        b_prime_params = 2.0 * np.random.randn(2*B, 2)\n",
    "    else:\n",
    "        b_prime_params = np.random.uniform(-10, 10, 2*B).reshape(-1, 2)\n",
    "    # b_prime_radius = np.linalg.norm(b_prime_params, axis=1).reshape(-1, 1)\n",
    "    b_prime_samples = np.vstack([sample_likelihood(theta0, 1) for theta0 in b_prime_params])\n",
    "    b_prime_test_statistics = np.vstack([log_posterior(theta0, x0) for (theta0, x0) in zip(b_prime_params, b_prime_samples)])\n",
    "    b_prime_ts = np.random.uniform(b_prime_test_statistics.min(), b_prime_test_statistics.max(), b_prime_test_statistics.shape)\n",
    "\n",
    "    augmented_inputs, rejection_indicators = np.hstack([b_prime_ts, b_prime_params]), (b_prime_ts > b_prime_test_statistics).astype(int)\n",
    "    return augmented_inputs, rejection_indicators\n",
    "\n",
    "augmented_inputs, rejection_indicators = sample_joint_distribution('prior', 10_000)\n",
    "augmented_inputs_test, rejection_indicators_test = sample_joint_distribution('uniform', 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from pygam import LogisticGAM, s, te, l, f\n",
    "import numpy as np\n",
    "\n",
    "class GAMWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, add_radius=True):\n",
    "        \"\"\"\n",
    "        add_radius: If True, expects X of shape (N, 3) and adds radius as 4th column\n",
    "                    If False, expects X of shape (N, 4) with radius already included\n",
    "        \"\"\"\n",
    "        self.add_radius = add_radius\n",
    "        self.classes_ = np.array([0, 1])\n",
    "\n",
    "    def _add_radius_feature(self, X):\n",
    "        \"\"\"Add radius as ||theta|| = sqrt(X[:, 1]^2 + X[:, 2]^2)\"\"\"\n",
    "        if not self.add_radius:\n",
    "            return X\n",
    "        \n",
    "        if X.shape[1] != 3:\n",
    "            raise ValueError(f\"Expected X with 3 columns when add_radius=True, got {X.shape[1]}\")\n",
    "        \n",
    "        radius = np.linalg.norm(X[:, [1, 2]], axis=1, keepdims=True)\n",
    "        return np.column_stack([X, radius])\n",
    "\n",
    "    def _build_formula(self):\n",
    "        \"\"\"Reconstruct the formula from config\"\"\"\n",
    "        formula = (\n",
    "            s(0, constraints='monotonic_inc', n_splines=12, spline_order=3) +\n",
    "            l(3) +\n",
    "            te(0, 3, n_splines=3, spline_order=2) +\n",
    "            s(3, constraints='concave', n_splines=6, spline_order=2)\n",
    "        )\n",
    "        return formula\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the GAM model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, 3)\n",
    "            Features [t, theta1, theta2]\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values\n",
    "        \"\"\"\n",
    "        # Add radius feature\n",
    "        X_with_radius = self._add_radius_feature(X)\n",
    "        \n",
    "        # Reconstruct the formula inside fit (after cloning)\n",
    "        self.gam_model_ = LogisticGAM(self._build_formula(), tol=1e-4)\n",
    "        self.gam_model_.gridsearch(\n",
    "            X_with_radius,\n",
    "            y,\n",
    "            lam=np.logspace(-1, 3, 9),\n",
    "            progress=False\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, 3)\n",
    "            Features [t, theta1, theta2]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        array of shape (n_samples,)\n",
    "            Predicted class labels\n",
    "        \"\"\"\n",
    "        X_with_radius = self._add_radius_feature(X)\n",
    "        return self.gam_model_.predict(X_with_radius)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, 3)\n",
    "            Features [t, theta1, theta2]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        array of shape (n_samples, 2)\n",
    "            Predicted probabilities for each class [P(class=0), P(class=1)]\n",
    "        \"\"\"\n",
    "        X_with_radius = self._add_radius_feature(X)\n",
    "        probs = self.gam_model_.predict_proba(X_with_radius)\n",
    "        return np.column_stack([1 - probs, probs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c40ff",
   "metadata": {},
   "source": [
    "# Estimate p-value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f07892",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GAMWrapper()\n",
    "estimator.fit(augmented_inputs, rejection_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c531984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Or visualize all terms\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "# for i, ax in enumerate(axs):\n",
    "#     XX = estimator.gam_model_.generate_X_grid(term=i)\n",
    "#     ax.plot(XX[:, estimator.gam_model_.terms[i].feature], \n",
    "#             estimator.gam_model_.partial_dependence(term=i, X=XX))\n",
    "#     ax.set_title(f'Term {i}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfbaf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "estimator_calibrated = CalibratedClassifierCV(\n",
    "    estimator=GAMWrapper(),\n",
    "    method='sigmoid',\n",
    "    cv=5,\n",
    "    n_jobs=1\n",
    ")\n",
    "estimator_calibrated.fit(X=augmented_inputs, y=rejection_indicators.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)  # Enable LaTeX\n",
    "plt.rc('font', family='serif')  # Use a serif font (e.g., Computer Modern)\n",
    "plt.rcParams['text.latex.preamble'] = r'''\n",
    "    \\usepackage{amsmath}  % For \\mathbb\n",
    "    \\usepackage{amssymb}  % For \\mathbb\n",
    "    \\usepackage{bm}       % For bold math symbols\n",
    "    \\usepackage{underscore} % If underscores are needed\n",
    "'''\n",
    "\n",
    "theta0s = [np.array([0., 0.]), np.array([4, 4]), np.array([8, 8])]\n",
    "\n",
    "for theta0 in theta0s:\n",
    "    theta_grid = np.hstack([np.linspace(0, 10, 100).reshape(-1, 1), theta0[0]*np.ones((100, 1))])\n",
    "    x_obs = sample_likelihood(theta0, 1)\n",
    "    t_vals = np.array([log_posterior(theta_i, x_obs) for theta_i in theta_grid]).reshape(-1, 1)\n",
    "\n",
    "    X = np.hstack([\n",
    "        t_vals,\n",
    "        theta_grid\n",
    "    ])\n",
    "    p_value_evaluated = estimator.predict_proba(X)[:, 1]\n",
    "    p_value_evaluated_calibrated = estimator_calibrated.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Exact\n",
    "    p_value_exact = np.array([\n",
    "        np.mean(t_vals[idx] > sample_log_posterior_dist(theta_i, 1_000)) for idx, theta_i in enumerate(theta_grid)\n",
    "    ])\n",
    "\n",
    "    # Create 2D histogram bins\n",
    "    # bins = [np.linspace(theta_grid[:, 0].min(), theta_grid[:, 0].max(), 25),\n",
    "    #         np.linspace(theta_grid[:, 1].min(), theta_grid[:, 1].max(), 25)]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "    # Plot exact p-values\n",
    "    h0 = axs[0].plot(theta_grid[:, 0], p_value_exact)\n",
    "    axs[0].set_title('exact')\n",
    "\n",
    "    # Plot GAM estimates\n",
    "    h1 = axs[1].plot(theta_grid[:, 0], p_value_evaluated)\n",
    "    axs[1].set_title('estimated (GAM)')\n",
    "\n",
    "    # Plot GAM-PS estimates\n",
    "    h2 = axs[2].plot(theta_grid[:, 0], p_value_evaluated_calibrated)\n",
    "    axs[2].set_title('estimated (GAM-PS)')\n",
    "\n",
    "    # fig.colorbar(h2, ax=axs[-1])\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.axvline(theta0[0], c='r', linestyle='--')\n",
    "        ax.set_xlabel('$\\\\theta_0^1$')\n",
    "        ax.set_ylabel('$\\\\alpha$')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "# Plot exact p-values\n",
    "h0 = axs[0].plot(theta_grid[:, 0], p_value_exact)\n",
    "axs[0].set_title('exact')\n",
    "\n",
    "# Plot GAM estimates\n",
    "h1 = axs[1].plot(theta_grid[:, 0], p_value_evaluated)\n",
    "axs[1].set_title('estimated (GAM)')\n",
    "\n",
    "# Plot GAM-PS estimates\n",
    "h2 = axs[2].plot(theta_grid[:, 0], p_value_evaluated_calibrated)\n",
    "axs[2].set_title('estimated (GAM-PS)')\n",
    "\n",
    "# fig.colorbar(h2, ax=axs[-1])\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axvline(theta0[0], c='r', linestyle='--')\n",
    "    ax.set_xlabel('$\\\\theta_0^1$')\n",
    "    ax.set_ylabel('$\\\\alpha$')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)  # Enable LaTeX\n",
    "plt.rc('font', family='serif')  # Use a serif font (e.g., Computer Modern)\n",
    "plt.rcParams['text.latex.preamble'] = r'''\n",
    "    \\usepackage{amsmath}  % For \\mathbb\n",
    "    \\usepackage{amssymb}  % For \\mathbb\n",
    "    \\usepackage{bm}       % For bold math symbols\n",
    "    \\usepackage{underscore} % If underscores are needed\n",
    "'''\n",
    "\n",
    "theta0s = [np.array([0., 0.]), np.array([4, 4]), np.array([8, 8])]\n",
    "\n",
    "for theta0 in theta0s:\n",
    "    theta_grid = np.random.uniform(-10, 10, 5_000).reshape(-1, 2)\n",
    "    # theta_grid = np.hstack([np.random.uniform(theta0[0] - 3, theta0[0] + 3, 100).reshape(-1, 1), np.random.uniform(theta0[1] - 3, theta0[1] + 3, 100).reshape(-1, 1)])\n",
    "    x_obs = sample_likelihood(theta0, 1)\n",
    "    t_vals = np.array([log_posterior(theta_i, x_obs) for theta_i in theta_grid]).reshape(-1, 1)\n",
    "\n",
    "    X = np.hstack([\n",
    "        t_vals,\n",
    "        theta_grid\n",
    "    ])\n",
    "    # X = np.hstack([X, np.linalg.norm(X[:, [1, 2]], axis=1).reshape(-1, 1)])\n",
    "    p_value_evaluated = estimator.predict_proba(X)[:, 1]\n",
    "    p_value_evaluated_calibrated = estimator_calibrated.predict_proba(X)[:, 1]\n",
    "\n",
    "    # # Exact\n",
    "    # p_value_exact = np.array([\n",
    "    #     np.mean(t_vals[idx] > sample_log_posterior_dist(theta_i, 500)) for idx, theta_i in enumerate(theta_grid)\n",
    "    # ])\n",
    "\n",
    "    gam_set_95 = theta_grid[p_value_evaluated > 0.05]\n",
    "    gam_set_68 = theta_grid[p_value_evaluated > 0.32]\n",
    "    gamps_set_95 = theta_grid[p_value_evaluated_calibrated > 0.05]\n",
    "    gamps_set_68 = theta_grid[p_value_evaluated_calibrated > 0.32]\n",
    "    # exact_set_95 = theta_grid[p_value_exact > 0.05]\n",
    "    # exact_set_68 = theta_grid[p_value_exact > 0.32]\n",
    "\n",
    "    # Create 2D histogram bins\n",
    "    bins = [np.linspace(theta_grid[:, 0].min(), theta_grid[:, 0].max(), 25),\n",
    "            np.linspace(theta_grid[:, 1].min(), theta_grid[:, 1].max(), 25)]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "    # # Plot exact p-values\n",
    "    # h0 = axs[0].hist2d(theta_grid[:, 0], theta_grid[:, 1], bins=bins, \n",
    "    #                     weights=p_value_exact, cmap='viridis', vmin=0, vmax=1)\n",
    "    # axs[0].set_title('exact')\n",
    "\n",
    "    # Plot GAM estimates\n",
    "    h1 = axs[1].hist2d(theta_grid[:, 0], theta_grid[:, 1], bins=bins,\n",
    "                        weights=p_value_evaluated, cmap='viridis', vmin=0, vmax=1)\n",
    "    axs[1].set_title('estimated (GAM)')\n",
    "\n",
    "    # Plot GAM-PS estimates\n",
    "    h2 = axs[2].hist2d(theta_grid[:, 0], theta_grid[:, 1], bins=bins,\n",
    "                        weights=p_value_evaluated_calibrated, cmap='viridis', vmin=0, vmax=1)\n",
    "    axs[2].set_title('estimated (GAM-PS)')\n",
    "\n",
    "    fig.colorbar(h2[3], ax=axs[-1])\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('$\\\\theta_0^1$')\n",
    "        ax.set_ylabel('$\\\\theta_0^2$')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "    # # Plot exact p-values\n",
    "    # h0 = axs[0].scatter(exact_set_95[:, 0], exact_set_95[:, 1], c='lightgreen')\n",
    "    # axs[0].scatter(exact_set_68[:, 0], exact_set_68[:, 1], c='darkgreen')\n",
    "    # axs[0].set_title('exact')\n",
    "\n",
    "    # Plot GAM estimates\n",
    "    h1 = axs[1].scatter(gam_set_95[:, 0], gam_set_95[:, 1], c='lightgreen')\n",
    "    axs[1].scatter(gam_set_68[:, 0], gam_set_68[:, 1], c='darkgreen')\n",
    "    axs[1].set_title('estimated (GAM)')\n",
    "\n",
    "    # Plot GAM-PS estimates\n",
    "    h2 = axs[2].scatter(gamps_set_95[:, 0], gamps_set_95[:, 1], c='lightgreen')\n",
    "    axs[2].scatter(gamps_set_68[:, 0], gamps_set_68[:, 1], c='darkgreen')\n",
    "    axs[2].set_title('estimated (GAM-PS)')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.scatter(theta0[0], theta0[1], c='r', marker='*')\n",
    "        ax.set_xlim(-10, 10)\n",
    "        ax.set_ylim(-10, 10)\n",
    "        ax.set_xlabel('$\\\\theta_0^1$')\n",
    "        ax.set_ylabel('$\\\\theta_0^2$')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "print(p_value_evaluated.max(), p_value_evaluated_calibrated.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "roc_display = RocCurveDisplay.from_estimator(estimator, augmented_inputs_test, rejection_indicators_test)\n",
    "plt.title('ROC Curve for Basic GAM')\n",
    "plt.show()\n",
    "\n",
    "roc_display = RocCurveDisplay.from_estimator(estimator_calibrated, augmented_inputs_test, rejection_indicators_test)\n",
    "plt.title('ROC Curve for Calibrated GAM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "for theta0, ax in zip([torch.tensor([0., 0.]), torch.tensor([3.5, 3.5]), torch.tensor([8., 8.])], axs):\n",
    "    t_range = np.linspace(-40, 10, 1000)\n",
    "\n",
    "    # Estimated\n",
    "    X = np.hstack([\n",
    "        t_range.reshape(-1, 1),\n",
    "        np.repeat(theta0.reshape(1, -1), 1_000, axis=0)\n",
    "    ])\n",
    "    # X = np.hstack([X, np.linalg.norm(X[:, [1, 2]], axis=1).reshape(-1, 1)])\n",
    "    p_value_evaluated = estimator.predict_proba(X)[:, 1]\n",
    "    p_value_evaluated_calibrated = estimator_calibrated.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Exact\n",
    "    log_posts = sample_log_posterior_dist(theta0.numpy(), n_samples=1_000)\n",
    "    log_posts_sorted = np.sort(log_posts)\n",
    "    quantiles = np.linspace(0, 1, len(log_posts_sorted))\n",
    "    q_extended = np.interp(t_range, log_posts_sorted, quantiles, left=0, right=1)\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(t_range, p_value_evaluated, label='estimated (GAM)', c='b', linewidth=5)\n",
    "    ax.plot(t_range, p_value_evaluated_calibrated, label='estimated (GAM-PS)', c='r', linestyle='--', linewidth=5)\n",
    "    ax.plot(t_range, q_extended, label='exact', c='g', linestyle=':', linewidth=5)\n",
    "    ax.set_xlabel('$\\log\\pi(\\\\theta_0\\\\vert X)$')\n",
    "    ax.set_ylabel('$\\\\alpha$')\n",
    "    ax.set_xlim(-40, 10)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(f'$\\\\theta_0=({theta0[0]}, {theta0[1]})$')\n",
    "    ax.legend()\n",
    "\n",
    "fig.suptitle('\\\\textbf{True \\& estimated p-values} (i.e.~$X\\sim p(X\\\\vert\\\\theta_0)$)', fontweight='bold', fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fed85a9",
   "metadata": {},
   "source": [
    "# From FMPE posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = 0\n",
    "experiment_dir = f'results/test/mixed_train'\n",
    "assets_dir = 'results/test/mixed_train'\n",
    "\n",
    "with open(f'{assets_dir}/fmpe_strong_prior.pkl', 'rb') as f:\n",
    "    fmpe_posterior = dill.load(f)\n",
    "with open(f'{experiment_dir}/lf2i_strong_prior.pkl', 'rb') as f:\n",
    "    lf2i = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca008fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings\n",
    "POI_DIM = 2  # parameter of interest\n",
    "PRIOR_LOC = [0, 0]\n",
    "PRIOR_VAR = 2.0 # (6*np.sqrt(2.0))**2\n",
    "POI_BOUNDS = {r'$\\theta_1$': (-10, 10), r'$\\theta_2$': (-10, 10)}\n",
    "PRIOR = MultivariateNormal(\n",
    "    loc=torch.Tensor(PRIOR_LOC), covariance_matrix=PRIOR_VAR*torch.eye(n=POI_DIM)\n",
    ")\n",
    "\n",
    "B = 50_000  # num simulations to estimate posterior and test statistics\n",
    "B_PRIME = 5_000  # num simulations to estimate critical values\n",
    "B_DOUBLE_PRIME = 5_000  # num simulations to do diagnostics\n",
    "EVAL_GRID_SIZE = 10_000  # num evaluation points over parameter space to construct confidence sets\n",
    "CONFIDENCE_LEVEL = 0.954, 0.683  # 0.99\n",
    "MIXING_PROPORTION = 0.0\n",
    "\n",
    "REFERENCE = PRIOR\n",
    "EVAL_GRID_DISTR = BoxUniform(\n",
    "    low=torch.tensor((POI_BOUNDS[r'$\\theta_1$'][0], POI_BOUNDS[r'$\\theta_2$'][0])),\n",
    "    high=torch.tensor((POI_BOUNDS[r'$\\theta_1$'][1], POI_BOUNDS[r'$\\theta_2$'][1]))\n",
    ")\n",
    "\n",
    "POSTERIOR_KWARGS = {\n",
    "    # 'norm_posterior': None\n",
    "}\n",
    "DEVICE = 'cpu'\n",
    "task = sbibm.get_task('gaussian_mixture')\n",
    "simulator = task.get_simulator()\n",
    "\n",
    "b_prime_params = REFERENCE.sample(sample_shape=(B_PRIME, ))\n",
    "b_prime_samples = simulator(b_prime_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15955f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf2i = LF2I(test_statistic=Posterior(poi_dim=2, estimator=fmpe_posterior, **POSTERIOR_KWARGS))\n",
    "b_prime_stats = lf2i.test_statistic.evaluate(parameters=b_prime_params, samples=b_prime_samples, mode='critical_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('b_prime.pkl', 'wb') as f:\n",
    "    dill.dump(\n",
    "        {\n",
    "            'params': b_prime_params,\n",
    "            'samples': b_prime_samples,\n",
    "            'stats': b_prime_stats\n",
    "        },\n",
    "        f\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(b_prime_params[:, 0], b_prime_params[:, 1], alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea317b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAMWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, add_radius=True):\n",
    "        \"\"\"\n",
    "        add_radius: If True, expects X of shape (N, 3) and adds radius as 4th column\n",
    "                    If False, expects X of shape (N, 4) with radius already included\n",
    "        \"\"\"\n",
    "        self.add_radius = add_radius\n",
    "        self.classes_ = np.array([0, 1])\n",
    "\n",
    "    def _add_radius_feature(self, X):\n",
    "        \"\"\"Add radius as ||theta|| = sqrt(X[:, 1]^2 + X[:, 2]^2)\"\"\"\n",
    "        if not self.add_radius:\n",
    "            return X\n",
    "        \n",
    "        if X.shape[1] != 3:\n",
    "            raise ValueError(f\"Expected X with 3 columns when add_radius=True, got {X.shape[1]}\")\n",
    "        \n",
    "        radius = np.linalg.norm(X[:, [1, 2]], axis=1, keepdims=True)\n",
    "        return np.column_stack([X, radius])\n",
    "\n",
    "    def _build_formula(self):\n",
    "        \"\"\"Reconstruct the formula from config\"\"\"\n",
    "        formula = (\n",
    "            s(0, constraints='monotonic_inc', n_splines=12, spline_order=3) +\n",
    "            l(3) +\n",
    "            # te(0, 3, n_splines=3, spline_order=2) +\n",
    "            s(3, constraints='concave', n_splines=6, spline_order=2)\n",
    "        )\n",
    "        return formula\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the GAM model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, 3)\n",
    "            Features [t, theta1, theta2]\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values\n",
    "        \"\"\"\n",
    "        # Add radius feature\n",
    "        X_with_radius = self._add_radius_feature(X)\n",
    "        \n",
    "        # Reconstruct the formula inside fit (after cloning)\n",
    "        self.gam_model_ = LogisticGAM(self._build_formula(), tol=1e-4)\n",
    "        self.gam_model_.gridsearch(\n",
    "            X_with_radius,\n",
    "            y,\n",
    "            lam=np.logspace(-1, 3, 9),\n",
    "            progress=False\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, 3)\n",
    "            Features [t, theta1, theta2]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        array of shape (n_samples,)\n",
    "            Predicted class labels\n",
    "        \"\"\"\n",
    "        X_with_radius = self._add_radius_feature(X)\n",
    "        return self.gam_model_.predict(X_with_radius)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, 3)\n",
    "            Features [t, theta1, theta2]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        array of shape (n_samples, 2)\n",
    "            Predicted probabilities for each class [P(class=0), P(class=1)]\n",
    "        \"\"\"\n",
    "        X_with_radius = self._add_radius_feature(X)\n",
    "        probs = self.gam_model_.predict_proba(X_with_radius)\n",
    "        return np.column_stack([1 - probs, probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lf2i.calibration.p_values import augment_calibration_set\n",
    "\n",
    "augmented_inputs_real, rejection_indicators_real = augment_calibration_set(\n",
    "    test_statistics=b_prime_stats,\n",
    "    poi=b_prime_params,\n",
    "    num_augment=10,\n",
    "    acceptance_region=lf2i.test_statistic.acceptance_region\n",
    ")\n",
    "estimator_real = GAMWrapper()\n",
    "estimator_real.fit(augmented_inputs_real, rejection_indicators_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bdc986",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)  # Enable LaTeX\n",
    "plt.rc('font', family='serif')  # Use a serif font (e.g., Computer Modern)\n",
    "plt.rcParams['text.latex.preamble'] = r'''\n",
    "    \\usepackage{amsmath}  % For \\mathbb\n",
    "    \\usepackage{amssymb}  % For \\mathbb\n",
    "    \\usepackage{bm}       % For bold math symbols\n",
    "    \\usepackage{underscore} % If underscores are needed\n",
    "'''\n",
    "\n",
    "theta0s = [np.array([0., 0.]), np.array([4, 4]), np.array([8, 8])]\n",
    "\n",
    "for theta0 in theta0s:\n",
    "    theta_grid = np.random.uniform(-10, 10, 2_000).reshape(-1, 2)\n",
    "    # theta_grid = np.hstack([np.random.uniform(theta0[0] - 3, theta0[0] + 3, 100).reshape(-1, 1), np.random.uniform(theta0[1] - 3, theta0[1] + 3, 100).reshape(-1, 1)])\n",
    "    x_obs = sample_likelihood(theta0, 1)\n",
    "    t_vals = np.array([log_posterior(theta_i, x_obs) for theta_i in theta_grid]).reshape(-1, 1)\n",
    "\n",
    "    X = np.hstack([\n",
    "        t_vals,\n",
    "        theta_grid\n",
    "    ])\n",
    "    # X = np.hstack([X, np.linalg.norm(X[:, [1, 2]], axis=1).reshape(-1, 1)])\n",
    "    p_value_evaluated = estimator_real.predict_proba(X)[:, 1]\n",
    "\n",
    "    # # Exact\n",
    "    # p_value_exact = np.array([\n",
    "    #     np.mean(t_vals[idx] > sample_log_posterior_dist(theta_i, 500)) for idx, theta_i in enumerate(theta_grid)\n",
    "    # ])\n",
    "\n",
    "    gam_set_95 = theta_grid[p_value_evaluated > 0.05]\n",
    "    gam_set_68 = theta_grid[p_value_evaluated > 0.32]\n",
    "    # exact_set_95 = theta_grid[p_value_exact > 0.05]\n",
    "    # exact_set_68 = theta_grid[p_value_exact > 0.32]\n",
    "\n",
    "    # Create 2D histogram bins\n",
    "    bins = [np.linspace(theta_grid[:, 0].min(), theta_grid[:, 0].max(), 25),\n",
    "            np.linspace(theta_grid[:, 1].min(), theta_grid[:, 1].max(), 25)]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    # # Plot exact p-values\n",
    "    # h0 = axs[0].hist2d(theta_grid[:, 0], theta_grid[:, 1], bins=bins, \n",
    "    #                     weights=p_value_exact, cmap='viridis', vmin=0, vmax=1)\n",
    "    # axs[0].set_title('exact')\n",
    "\n",
    "    # Plot GAM estimates\n",
    "    h1 = axs[1].hist2d(theta_grid[:, 0], theta_grid[:, 1], bins=bins,\n",
    "                        weights=p_value_evaluated, cmap='viridis', vmin=0, vmax=1)\n",
    "    axs[1].set_title('estimated (GAM)')\n",
    "\n",
    "    # fig.colorbar(h2[3], ax=axs[-1])\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('$\\\\theta_0^1$')\n",
    "        ax.set_ylabel('$\\\\theta_0^2$')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    # # Plot exact p-values\n",
    "    # h0 = axs[0].scatter(exact_set_95[:, 0], exact_set_95[:, 1], c='lightgreen')\n",
    "    # axs[0].scatter(exact_set_68[:, 0], exact_set_68[:, 1], c='darkgreen')\n",
    "    # axs[0].set_title('exact')\n",
    "\n",
    "    # Plot GAM estimates\n",
    "    h1 = axs[1].scatter(gam_set_95[:, 0], gam_set_95[:, 1], c='lightgreen')\n",
    "    axs[1].scatter(gam_set_68[:, 0], gam_set_68[:, 1], c='darkgreen')\n",
    "    axs[1].set_title('estimated (GAM)')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.scatter(theta0[0], theta0[1], c='r', marker='*')\n",
    "        ax.set_xlim(-10, 10)\n",
    "        ax.set_ylim(-10, 10)\n",
    "        ax.set_xlabel('$\\\\theta_0^1$')\n",
    "        ax.set_ylabel('$\\\\theta_0^2$')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
